{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "transform = torch.nn.Sequential(\n",
    "    v2.Resize(256),\n",
    "    v2.RandomRotation(30),\n",
    "    v2.RandomCrop(64),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(\n",
    "        [0.5, 0.5, 0.5], \n",
    "        [0.5, 0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"http://localhost:8080/isalive\")\n",
    "print(r)\n",
    "# <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on local container\n",
    "\n",
    "import base64\n",
    "\n",
    "with open(\"./test_image.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "r = requests.post(\"http://localhost:8080/predict\", json={\n",
    "    \"instances\": [{\"image\": str(encoded_string)}]\n",
    "})\n",
    "print(r)\n",
    "# <Response [200]>\n",
    "\n",
    "r_json = r.json()\n",
    "print(r_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.getcwd() + \"/psychic-surf-404204-7c8e524715fa.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "\n",
    "def predict_custom_trained_model_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    instances: Union[Dict, List[Dict]],\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    \"\"\"\n",
    "    `instances` can be either single instance of type dict or a list\n",
    "    of instances.\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    instances = instances if type(instances) == list else [instances]\n",
    "    instances = [\n",
    "        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances\n",
    "    ]\n",
    "    parameters_dict = {}\n",
    "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # The predictions are a google.protobuf.Value representation of the model's predictions.\n",
    "    return response.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_custom_trained_model_sample(\n",
    "    project=\"601592189510\",\n",
    "    endpoint_id=\"6377996472868143104\",\n",
    "    location=\"us-central1\",\n",
    "    instances={ \"image\": str(encoded_string) }\n",
    ")\n",
    "\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on Google Cloud\n",
    "\n",
    "with open(\"./test_image.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "r = requests.post(\"https://us-central1-aiplatform.googleapis.com/v1/projects/601592189510/locations/us-central1/endpoints/6377996472868143104:predict\", json={\n",
    "    \"instances\": [{\"image\": str(encoded_string)}]\n",
    "})\n",
    "print(r)\n",
    "# <Response [200]>\n",
    "\n",
    "r_json = r.json()\n",
    "print(r_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
